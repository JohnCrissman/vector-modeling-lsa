{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "similarity_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RAwRHVNTIuJr",
        "CN2zxwTFKYhs"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO3T/LGK/H9Ybhke2ESa1e0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marianelamin/vector-modeling-lsa/blob/master/similarity_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOwmGSA2Hd8p",
        "colab_type": "text"
      },
      "source": [
        "#Neccesary files\n",
        "\n",
        "\n",
        "I need the `nlu_helper` folder in order to run this notebook. I will mount my drive, but you can clone the folders and upload it here.  It might take some time due to the size of the models (~300MB)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAwRHVNTIuJr",
        "colab_type": "text"
      },
      "source": [
        "## Uploading `nlu_helper` folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aMs6e1PIzWP",
        "colab_type": "text"
      },
      "source": [
        "1. Drag and drop `nlu_helper` folder to the left window under files.\n",
        "2. change the directory to nlu_helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2bx4bjVIP8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/nlu_helper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSi0dpHMIcf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGXrXt3LIS8B",
        "colab_type": "text"
      },
      "source": [
        "## Mounting my drive\n",
        "\n",
        "To mount my google drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-4lFa_LklUI",
        "colab_type": "code",
        "outputId": "b826fdfd-db5c-40fa-db94-ec895fb73f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yz39CmEShOKe",
        "colab_type": "text"
      },
      "source": [
        "change directory to custom python module:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9PDT9fta1RY",
        "colab_type": "code",
        "outputId": "3015bcb8-2c54-4f1c-df1f-79128f6260e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/'My Drive'/NEIU-CS/'cs490 Masters Project'/notebook/nlu_helper"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NEIU-CS/cs490 Masters Project/notebook/nlu_helper\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GklH7G9DjDl2",
        "colab_type": "text"
      },
      "source": [
        "list of files on desired working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty4Y35S2aPma",
        "colab_type": "code",
        "outputId": "319ea98b-286e-47d6-88bc-d577c3b383c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls /content/drive/'My Drive'/NEIU-CS/'cs490 Masters Project'/notebook/nlu_helper"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__.py  \u001b[0m\u001b[01;34mlogs\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  read_model.py  \u001b[01;34mresources\u001b[0m/  utility.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Dv16qAhYxF",
        "colab_type": "text"
      },
      "source": [
        "list of files on current working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmhA4hG0a-ao",
        "colab_type": "code",
        "outputId": "8e161980-2cce-4138-8a17-d49f202b9e5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__init__.py  \u001b[0m\u001b[01;34mlogs\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  read_model.py  \u001b[01;34mresources\u001b[0m/  utility.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovQ-37q0lc7N",
        "colab_type": "text"
      },
      "source": [
        "#Comparing two texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeBZQvIvlw8V",
        "colab_type": "text"
      },
      "source": [
        "## Importing modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpdSDfV5Yvty",
        "colab_type": "text"
      },
      "source": [
        "#### Importing python modules\n",
        "These modules help us deal with the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOtyRwY8W9H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cad776a8-5d8d-4650-df65-75d9ba351f22"
      },
      "source": [
        "from traceback import print_exc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "from sklearn.feature_extraction import stop_words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiEXImrJY2BT",
        "colab_type": "text"
      },
      "source": [
        "####Importing custome modules\n",
        "* *utility* has functions.\n",
        "* *read_model* has the classes needed to load the model, process the text and compare two sentences using cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukX6T4xMY8xF",
        "colab_type": "code",
        "outputId": "5a8ff9c5-a6c6-4fda-de33-eb67d5d5eb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# current path since I changed the directory after mounting my drive\n",
        "PROJECT_PATH = os.path.dirname(os.path.abspath('.'))\n",
        "\n",
        "# print(PROJECT_PATH)\n",
        "# print(sys.path)\n",
        "if PROJECT_PATH not in sys.path:\n",
        "    sys.path.append(PROJECT_PATH)\n",
        "\n",
        "from nlu_helper.read_model import MatrixModel, SentenceProcessor\n",
        "from nlu_helper.utility import load_json2py, create_a_logger, resources_folder, log_and_print, file2pickle\n",
        "from nlu_helper.utility import create_results_directory_if_needed\n",
        "\n",
        "print('Load modules from: ', PROJECT_PATH)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load modules from:  /content/drive/My Drive/NEIU-CS/cs490 Masters Project/notebook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FYRXemlus8M",
        "colab_type": "text"
      },
      "source": [
        "## Loading and Using a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzd9tl8093IO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls resources/all_senate_speeches/ | grep .pkl # check which models have already been uploaded into the google colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8odFZM9SfZv",
        "colab_type": "text"
      },
      "source": [
        "A model is needed in order to compare two texts.  Down below there is a list of available models. These name of each models describes how it was generated.\n",
        "\n",
        "* `lsa` or `docbyterm`: implementing LSA or not\n",
        "* if `lsa` applied, `dim` should specify the number of dimensions\n",
        "* `count`, `tfidf` or `zeroone` defines the type of scoring when vectorizing the corpus. *count* refers to the frequency of the word in the document; *zeroone* to the existence or not of the word in the document; *tfidf* to the term frequecy inverse document frequency (importance of the word in the document).\n",
        "* `stop` if stopwords were removed from the corpus prior to the model generation\n",
        "* `RxC` *R* number of rows (words) in the model, *C* number of columns.\n",
        "\n",
        "From the recostructed matrix taking only the fisrt *C* columns.\n",
        "\n",
        "**!! Important !!**\n",
        "\n",
        "There is an issue with the memory.  This demo only works (in this notebook) for models that use LSA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZM0c0rhS3MZ",
        "colab_type": "text"
      },
      "source": [
        "### Selecting the model\n",
        "Run the snippet to load the selected model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skMA9whY799Z",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "6f2aa335-8e41-45e5-d2e5-b793c154bfb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#@title Select the model\n",
        "model_filename = \"all_senate_speeches-min_df_2-lsa-dim300-zeroone-stop_69414x1000\" #@param [\"all_senate_speeches-min_df_2-lsa-dim100-count_69724x1000\", \"all_senate_speeches-min_df_2-lsa-dim100-count-stop_69414x1000\", \"all_senate_speeches-min_df_2-lsa-dim100-tfidf_69724x1000\", \"all_senate_speeches-min_df_2-lsa-dim100-tfidf-stop_69414x1000\", \"all_senate_speeches-min_df_2-lsa-dim100-zeroone_69724x1000\", \"all_senate_speeches-min_df_2-lsa-dim100-zeroone-stop_69414x1000\", \"all_senate_speeches-min_df_2-lsa-dim300-count_69724x1000\", \"all_senate_speeches-min_df_2-lsa-dim300-count-stop_69414x1000\", \"all_senate_speeches-min_df_2-lsa-dim300-tfidf_69724x1000\", \"all_senate_speeches-min_df_2-lsa-dim300-tfidf-stop_69414x1000\", \"all_senate_speeches-min_df_2-lsa-dim300-zeroone_69724x1000\", \"all_senate_speeches-min_df_2-lsa-dim300-zeroone-stop_69414x1000\"]\n",
        "\n",
        "model_filepath = 'all_senate_speeches/'+ model_filename\n",
        "print('file: ', model_filepath)\n",
        "\n",
        "\n",
        "try:\n",
        "  #create the matrix model, this reads and holds the data\n",
        "  matrix_model = MatrixModel(model_filepath, logger=None)\n",
        "\n",
        "  #create the processor object, this takes the model.\n",
        "  sp = SentenceProcessor(matrix_model)\n",
        "\n",
        "  print('\\t- MatrixModel loaded!')\n",
        "  print('\\t- SentenceProcessor ready!')\n",
        "except Exception:\n",
        "  print('There was an error with the model.  Either not found or you are attepting to use a non-lsa')\n",
        "  print_exc()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file:  all_senate_speeches/all_senate_speeches-min_df_2-lsa-dim300-zeroone-stop_69414x1000\n",
            "\t- MatrixModel loaded!\n",
            "\t- SentenceProcessor ready!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTwrtxKhKP9l",
        "colab_type": "text"
      },
      "source": [
        "### 1. Using the model to compare\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBqo0lMdV8sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp.args"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7E4TYj5Eo6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence1= 'May the force be with you'\n",
        "sentence2= 'cancer begings in the cells'\n",
        "\n",
        "s1_tokenized = sp.tokenize_sentence(sentence1)\n",
        "print(s1_tokenized)\n",
        "sentence1_vector = sp.get_sentence_vector(s1_tokenized)\n",
        "# print(sentence1_vector)\n",
        "\n",
        "s2_tokenized = sp.tokenize_sentence(sentence2)\n",
        "print(s2_tokenized)\n",
        "sentence2_vector = sp.get_sentence_vector(s2_tokenized)\n",
        "# print(sentence2_vector)\n",
        "\n",
        "sp.get_sentence_match(sentence1, sentence2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APrbmqsPVeRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check it the words are in English_stop_words set\n",
        "# print(stop_words.ENGLISH_STOP_WORDS)\n",
        "def which_were_removed(sentence):\n",
        "  print('\\nsentence: ', sentence)\n",
        "  for word in sentence.lower().split():\n",
        "    print('\\t[x]' if word in stop_words.ENGLISH_STOP_WORDS else '\\t[ ]', word)\n",
        "\n",
        "which_were_removed(sentence1)\n",
        "which_were_removed(sentence2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2zxwTFKYhs",
        "colab_type": "text"
      },
      "source": [
        "### 2. Automatic multiple comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdE5x8S1Y9ix",
        "colab_type": "text"
      },
      "source": [
        "#### Defining the Model Applier class.\n",
        "This is the class that will apply the model selected and provide us with the result. We do not need a log file, because everything will be printed on the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uanSoaM5ZOiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelApplier:\n",
        "\n",
        "    def __init__(self, filename):\n",
        "        # self.logger = create_a_logger('read_model.log')\n",
        "        # self.logger.info('*************************************** STARTING TO APPLY MODEL')\n",
        "        # self.logger.info('model file used: ' + filename)\n",
        "        # self.logger.debug('creating the object of the MatrixModel')\n",
        "        self.logger = None\n",
        "\n",
        "        self.matrix_model = MatrixModel(filename, logger=self.logger)\n",
        "\n",
        "        # self.logger.debug('finish creating the MatrixModel object')\n",
        "        # print(matrix_model.args)\n",
        "        self.sp = SentenceProcessor(self.matrix_model, logger=self.logger)\n",
        "        # self.model_filename = filename\n",
        "\n",
        "    def paragraph_vs_sentences_similarities(self, real_answer: str, given_answers: list) -> list:\n",
        "        \"\"\"\n",
        "        :param real_answer: is a string containing the systems sentence/paragraph that we need to compare against\n",
        "        :param given_answers: is a list of the possible answers that could have been given by the human user\n",
        "        returns a list containing all cosine similarity values that were computed from comparing the answer to each\n",
        "         possible answer on the question dictionary\n",
        "        \"\"\"\n",
        "        r_tok = self.sp.tokenize_sentence(real_answer)\n",
        "        real_sentence_vector = self.sp.get_sentence_vector(r_tok)\n",
        "        array_sim = list()\n",
        "\n",
        "        for given_answer in given_answers:\n",
        "            # print(given_answer)\n",
        "            g_tok = self.sp.tokenize_sentence(given_answer['text'])\n",
        "            sim = self.sp.cos_sim(real_sentence_vector,\n",
        "                                  self.sp.get_sentence_vector(g_tok))\n",
        "            array_sim.append(sim)\n",
        "            # print('result: ', sim)\n",
        "\n",
        "        return array_sim\n",
        "\n",
        "    def sort_similarity(self, cosine_similarity_results, question: dict) -> dict:\n",
        "        # Add two more columns with 'id', 'text' tags\n",
        "        ids = [q['id'] for q in question['possible_answers']]\n",
        "        texts = [q['text'] for q in question['possible_answers']]\n",
        "        pdf = pd.DataFrame({'id': ids, 'similarity': np.asarray(cosine_similarity_results), 'text': texts},\n",
        "                           index=ids)\n",
        "\n",
        "        sorted_pdf = pdf.sort_values(by='similarity', ascending=False)\n",
        "        self.generate_log_similarities_report(question, sorted_pdf)\n",
        "\n",
        "        final_order = [i + 1 for i in range(len(sorted_pdf.values))]\n",
        "        sorted_pdf.insert(1, 'rank', final_order)\n",
        "\n",
        "        item = {\n",
        "            \"item_id\": question['lp_id'],\n",
        "            \"item_text\": question['answer'],\n",
        "            \"result_as_pdf\": json.loads(sorted_pdf.to_json()),\n",
        "            \"result_only_id\": sorted_pdf.index.tolist()\n",
        "        }\n",
        "        return item\n",
        "\n",
        "    def generate_log_similarities_report(self, question, pdf):\n",
        "        m = '\\n--------------------------------------- \\nRESULTS \\nCompare: ' + str(question['answer']) \\\n",
        "            + '\\nTo: \\n' + str(pdf) \\\n",
        "            + '\\n---------------------------------------'\n",
        "        log_and_print(m, self.logger)\n",
        "\n",
        "    def save_model_results(self, output_model_results, items, path_testfile):\n",
        "        with open(output_model_results + '.json', 'w') as fp:\n",
        "            json.dump({\n",
        "                \"testfile\": path_testfile,\n",
        "                \"model\": {\n",
        "                    \"filename\": self.matrix_model.filename,\n",
        "                    \"args\": self.matrix_model.args\n",
        "                },\n",
        "                \"items\": items\n",
        "            },\n",
        "                fp)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfUgpHiiZPmM",
        "colab_type": "text"
      },
      "source": [
        "#### Defining multiple sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF2nvfWDs4CT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questionaire = [\n",
        "                {\n",
        "                  \"lp_id\": \"LP2\",\n",
        "                  \"answer\": \"cancer begins in cells\",\n",
        "                  \"possible_answers\": [\n",
        "                      {\n",
        "                        \"id\": \"SP1\", \"text\": \"May the force be with you.\"\n",
        "                      }\n",
        "                    ]\n",
        "                }\n",
        "              ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIJj59aPSZnH",
        "colab_type": "text"
      },
      "source": [
        "#### Getting automatic ordered results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hPO7MoSScpO",
        "colab_type": "code",
        "outputId": "4c974028-cd62-4229-cc90-db3a166c7c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print('Model to use: ', model_filepath)\n",
        "\n",
        "ma = ModelApplier(model_filepath)\n",
        "\n",
        "items = list()\n",
        "for question in questionaire:\n",
        "    possible_answers = question['possible_answers']\n",
        "    answer = question['answer']\n",
        "\n",
        "    if len(possible_answers) != 0:\n",
        "        cos_sim_results = ma.paragraph_vs_sentences_similarities(real_answer=answer,\n",
        "                                                                  given_answers=possible_answers)\n",
        "        print(cos_sim_results)\n",
        "        item = ma.sort_similarity(cos_sim_results, question)\n",
        "        items.append(item)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model to use:  all_senate_speeches/all_senate_speeches-min_df_2-lsa-dim100-count-stop_69414x1000\n",
            "[0.20551174879074097]\n",
            "\n",
            "--------------------------------------- \n",
            "RESULTS \n",
            "Compare: cancer begins in cells\n",
            "To: \n",
            "      id  similarity                        text\n",
            "SP1  SP1    0.205512  May the force be with you.\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNl-5p_tcA2",
        "colab_type": "code",
        "outputId": "c9d0cac0-be40-4a6e-f9b6-39c1e2367f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(items)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'item_id': 'LP2', 'item_text': 'cancer begins in cells', 'result_as_pdf': {'id': {'SP1': 'SP1'}, 'rank': {'SP1': 1}, 'similarity': {'SP1': 0.2055117488}, 'text': {'SP1': 'May the force be with you.'}}, 'result_only_id': ['SP1']}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}